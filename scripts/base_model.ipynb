{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SQL Server', 'ODBC Driver 17 for SQL Server', 'SQL Server Native Client RDA 11.0', 'Microsoft Access Driver (*.mdb, *.accdb)', 'Microsoft Excel Driver (*.xls, *.xlsx, *.xlsm, *.xlsb)', 'Microsoft Access Text Driver (*.txt, *.csv)', 'Microsoft Access dBASE Driver (*.dbf, *.ndx, *.mdx)']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Data Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Model Evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import random\n",
    "random.seed(100)\n",
    "\n",
    "import time\n",
    "import pyodbc\n",
    "print(pyodbc.drivers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sql_connection(server, database, username, password, driver='{ODBC Driver 17 for SQL Server}'):\n",
    "    \"\"\"\n",
    "    Establish a connection to a SQL Server database using pyodbc.\n",
    "\n",
    "    Parameters:\n",
    "    - server (str): The SQL Server address (e.g., 'localhost' or server IP).\n",
    "    - database (str): The name of the database you want to connect to.\n",
    "    - username (str): SQL Server username.\n",
    "    - password (str): SQL Server password.\n",
    "    - driver (str): ODBC driver to use. Default is '{ODBC Driver 17 for SQL Server}'.\n",
    "\n",
    "    Returns:\n",
    "    - conn: A pyodbc connection object if successful.\n",
    "    \"\"\"\n",
    "    connection_string = f\"\"\"\n",
    "        DRIVER={driver};\n",
    "        SERVER={server};\n",
    "        DATABASE={database};\n",
    "        UID={username};\n",
    "        PWD={password};\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = pyodbc.connect(connection_string)\n",
    "        print(\"Connection established successfully!\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to connect to the database. Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_data(conn, query):\n",
    "    \"\"\"\n",
    "    Execute a SQL query and fetch results as a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - conn: A pyodbc connection object.\n",
    "    - query (str): The SQL query to be executed.\n",
    "    \n",
    "    Returns:\n",
    "    - df: A pandas DataFrame containing the query result.\n",
    "    \"\"\"\n",
    "    start_time = time.time()  # Start time measurement\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(query)\n",
    "        \n",
    "        # Fetch all results from the query\n",
    "        rows = cursor.fetchall()\n",
    "        \n",
    "        # Get column names from cursor\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "        \n",
    "        # Create a pandas DataFrame from the results\n",
    "        df = pd.DataFrame.from_records(rows, columns=columns)\n",
    "        \n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"Error executing query: {e}\")\n",
    "        return None\n",
    "    \n",
    "    finally:\n",
    "        cursor.close()\n",
    "    \n",
    "    end_time = time.time()  # End time measurement\n",
    "    execution_time = end_time - start_time  # Calculate execution time\n",
    "    \n",
    "    # Print the DataFrame and execution time\n",
    "    print(f\"Query executed in: {execution_time:.4f} seconds\")\n",
    "    \n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = 'ROHIT'     \n",
    "database = 'MedicareClaim'  \n",
    "username = 'rohit_kosamkar'       \n",
    "password = 'September@2024' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established successfully!\n"
     ]
    }
   ],
   "source": [
    "# Establish connection\n",
    "conn = create_sql_connection(server, database, username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed in: 0.0245 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BeneID</th>\n",
       "      <th>DOB</th>\n",
       "      <th>DOD</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>RenalDiseaseIndicator</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>NoOfMonths_PartACov</th>\n",
       "      <th>NoOfMonths_PartBCov</th>\n",
       "      <th>ChronicCond_Alzheimer</th>\n",
       "      <th>ChronicCond_Heartfailure</th>\n",
       "      <th>ChronicCond_KidneyDisease</th>\n",
       "      <th>ChronicCond_Cancer</th>\n",
       "      <th>ChronicCond_ObstrPulmonary</th>\n",
       "      <th>ChronicCond_Depression</th>\n",
       "      <th>ChronicCond_Diabetes</th>\n",
       "      <th>ChronicCond_IschemicHeart</th>\n",
       "      <th>ChronicCond_Osteoporasis</th>\n",
       "      <th>ChronicCond_rheumatoidarthritis</th>\n",
       "      <th>ChronicCond_stroke</th>\n",
       "      <th>IPAnnualReimbursementAmt</th>\n",
       "      <th>IPAnnualDeductibleAmt</th>\n",
       "      <th>OPAnnualReimbursementAmt</th>\n",
       "      <th>OPAnnualDeductibleAmt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BENE100000</td>\n",
       "      <td>1938-03-01</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>430</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BENE100001</td>\n",
       "      <td>1939-08-01</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>420</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2530</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BENE100002</td>\n",
       "      <td>1938-09-01</td>\n",
       "      <td>NA</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12250</td>\n",
       "      <td>1068</td>\n",
       "      <td>1760</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BENE100003</td>\n",
       "      <td>1950-06-01</td>\n",
       "      <td>NA</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>90</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BENE100004</td>\n",
       "      <td>1943-06-01</td>\n",
       "      <td>NA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>15</td>\n",
       "      <td>210</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14270</td>\n",
       "      <td>2136</td>\n",
       "      <td>1880</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       BeneID         DOB DOD Gender  Race RenalDiseaseIndicator State  \\\n",
       "0  BENE100000  1938-03-01  NA      1     1                     0    49   \n",
       "1  BENE100001  1939-08-01  NA      1     1                     0    33   \n",
       "2  BENE100002  1938-09-01  NA      2     2                     0    33   \n",
       "3  BENE100003  1950-06-01  NA      2     3                     0    22   \n",
       "4  BENE100004  1943-06-01  NA      2     1                     Y    15   \n",
       "\n",
       "   County  NoOfMonths_PartACov  NoOfMonths_PartBCov  ChronicCond_Alzheimer  \\\n",
       "0     430                   12                   12                      2   \n",
       "1     420                   12                   12                      1   \n",
       "2      20                   12                   12                      1   \n",
       "3      90                   12                   12                      2   \n",
       "4     210                   12                   12                      2   \n",
       "\n",
       "   ChronicCond_Heartfailure  ChronicCond_KidneyDisease  ChronicCond_Cancer  \\\n",
       "0                         2                          2                   2   \n",
       "1                         2                          2                   2   \n",
       "2                         1                          2                   2   \n",
       "3                         2                          2                   2   \n",
       "4                         1                          1                   2   \n",
       "\n",
       "   ChronicCond_ObstrPulmonary  ChronicCond_Depression  ChronicCond_Diabetes  \\\n",
       "0                           2                       2                     2   \n",
       "1                           2                       2                     2   \n",
       "2                           1                       1                     1   \n",
       "3                           2                       2                     2   \n",
       "4                           1                       2                     1   \n",
       "\n",
       "   ChronicCond_IschemicHeart  ChronicCond_Osteoporasis  \\\n",
       "0                          1                         2   \n",
       "1                          1                         1   \n",
       "2                          1                         2   \n",
       "3                          1                         2   \n",
       "4                          1                         1   \n",
       "\n",
       "   ChronicCond_rheumatoidarthritis  ChronicCond_stroke  \\\n",
       "0                                2                   2   \n",
       "1                                2                   1   \n",
       "2                                2                   1   \n",
       "3                                2                   2   \n",
       "4                                2                   2   \n",
       "\n",
       "   IPAnnualReimbursementAmt  IPAnnualDeductibleAmt  OPAnnualReimbursementAmt  \\\n",
       "0                         0                      0                       120   \n",
       "1                         0                      0                      2530   \n",
       "2                     12250                   1068                      1760   \n",
       "3                         0                      0                       300   \n",
       "4                     14270                   2136                      1880   \n",
       "\n",
       "   OPAnnualDeductibleAmt  \n",
       "0                     30  \n",
       "1                    540  \n",
       "2                    660  \n",
       "3                     20  \n",
       "4                    700  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bene_df  = query_data(conn, \"select top 10 * from beneficiarydata\")\n",
    "bene_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up MLflow Tracking with SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/04 18:28:40 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2024/10/04 18:28:41 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl MSSQLImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
      "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "d:\\workspace\\git_projects\\Medicare-Claim-Fraud-Detection\\.venv\\lib\\site-packages\\alembic\\ddl\\mssql.py:123: UserWarning: MS-SQL ALTER COLUMN operations that specify type_= should also specify a nullable= or existing_nullable= argument to avoid implicit conversion of NOT NULL columns to NULL.\n",
      "  util.warn(\n",
      "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "INFO  [alembic.runtime.migration] Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "INFO  [alembic.runtime.migration] Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "INFO  [alembic.runtime.migration] Context impl MSSQLImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume transactional DDL.\n",
      "2024/10/04 18:28:42 INFO mlflow.tracking.fluent: Experiment with name 'MedicareClaim_Fraud_Detection' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "try:\n",
    "    # Set MLflow Tracking URI using SQL Server and Windows Authentication\n",
    "    mlflow.set_tracking_uri(\"mssql+pyodbc://ROHIT/MedicareClaim?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes\")\n",
    " \n",
    "    # Name the experiment\n",
    "    mlflow.set_experiment(\"MedicareClaim_Fraud_Detection\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful! Here are the tables in the database:\n",
      "Beneficiarydata\n",
      "Inpatientdata\n",
      "Outpatientdata\n",
      "experiments\n",
      "runs\n",
      "tags\n",
      "metrics\n",
      "params\n",
      "alembic_version\n",
      "experiment_tags\n",
      "latest_metrics\n",
      "registered_models\n",
      "model_versions\n",
      "registered_model_tags\n",
      "model_version_tags\n",
      "registered_model_aliases\n",
      "datasets\n",
      "inputs\n",
      "input_tags\n",
      "trace_info\n",
      "trace_tags\n",
      "trace_request_metadata\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sqlalchemy import create_engine, text\n",
    "import pandas as pd\n",
    "\n",
    "# Use a raw string to handle backslashes in the server name\n",
    "mlflow_tracking_uri = (\n",
    "    r\"mssql+pyodbc://ROHIT/MedicareClaim\"\n",
    "    \"?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes\"\n",
    ")\n",
    " \n",
    "# Set the MLflow Tracking URI\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    " \n",
    "try:\n",
    "    # Create an SQLAlchemy engine\n",
    "    engine = create_engine(mlflow_tracking_uri)\n",
    " \n",
    "    # Test the connection by running a simple query\n",
    "    with engine.connect() as connection:\n",
    "        # Use the text() function to create a SQL statement\n",
    "        query = text(\"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES\")\n",
    "        result = connection.execute(query)\n",
    " \n",
    "        # Fetch all the results and display them\n",
    "        tables = result.fetchall()\n",
    " \n",
    "        # Print the list of tables\n",
    "        print(\"Connection successful! Here are the tables in the database:\")\n",
    "        for table in tables:\n",
    "            print(table[0])\n",
    " \n",
    "    # Name the experiment (if connection is successful)\n",
    "    mlflow.set_experiment(\"MedicareClaim_Fraud_Detection\")\n",
    " \n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(558138, 35)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'../data/interim/model_data.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Separate the classes\n",
    "# df_class_0 = data[data['PotentialFraud'] == 0]\n",
    "# df_class_1 = data[data['PotentialFraud'] == 1]\n",
    "\n",
    "# # Define the number of samples you want to keep from class 0\n",
    "# num_class_1 = len(df_class_1)\n",
    "# df_class_0_balanced = df_class_0.sample(num_class_1, random_state=42)  # Randomly sample from class 0\n",
    "\n",
    "# # Combine the balanced classes\n",
    "# df_balanced = pd.concat([df_class_0_balanced, df_class_1])\n",
    "\n",
    "# # Shuffle the dataset to mix the classes\n",
    "# df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_encoded.drop(columns={'ClaimID', 'Provider'}).corr().to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PotentialFraud\n",
       "0    345369\n",
       "1    212769\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['PotentialFraud'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(558138, 37)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### One-hot encoding\n",
    "cat_cols = ['SamePhysician', 'OPD_Flag', 'Gender',\n",
    "       'Race', 'RenalDiseaseIndicator', 'ChronicCond_Alzheimer',\n",
    "       'ChronicCond_Heartfailure', 'ChronicCond_KidneyDisease',\n",
    "       'ChronicCond_Cancer', 'ChronicCond_ObstrPulmonary',\n",
    "       'ChronicCond_Depression', 'ChronicCond_Diabetes',\n",
    "       'ChronicCond_IschemicHeart', 'ChronicCond_Osteoporasis',\n",
    "       'ChronicCond_rheumatoidarthritis', 'ChronicCond_stroke']\n",
    "\n",
    "data_encoded = pd.get_dummies(data, columns = cat_cols,drop_first=True)\n",
    "data_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ClaimID</th>\n",
       "      <th>Provider</th>\n",
       "      <th>InscClaimAmtReimbursed</th>\n",
       "      <th>DeductibleAmtPaid</th>\n",
       "      <th>ClaimPeriod</th>\n",
       "      <th>TimeInHptal</th>\n",
       "      <th>Diagnosis Count</th>\n",
       "      <th>Procedures Count</th>\n",
       "      <th>PotentialFraud</th>\n",
       "      <th>FraudHistory</th>\n",
       "      <th>NoOfMonths_PartACov</th>\n",
       "      <th>NoOfMonths_PartBCov</th>\n",
       "      <th>IPAnnualReimbursementAmt</th>\n",
       "      <th>IPAnnualDeductibleAmt</th>\n",
       "      <th>OPAnnualReimbursementAmt</th>\n",
       "      <th>OPAnnualDeductibleAmt</th>\n",
       "      <th>Age</th>\n",
       "      <th>ChronicDisease_Count</th>\n",
       "      <th>SamePhysician_Yes</th>\n",
       "      <th>OPD_Flag_Yes</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Race_Hispanic</th>\n",
       "      <th>Race_Other</th>\n",
       "      <th>Race_White</th>\n",
       "      <th>RenalDiseaseIndicator_Yes</th>\n",
       "      <th>ChronicCond_Alzheimer_Yes</th>\n",
       "      <th>ChronicCond_Heartfailure_Yes</th>\n",
       "      <th>ChronicCond_KidneyDisease_Yes</th>\n",
       "      <th>ChronicCond_Cancer_Yes</th>\n",
       "      <th>ChronicCond_ObstrPulmonary_Yes</th>\n",
       "      <th>ChronicCond_Depression_Yes</th>\n",
       "      <th>ChronicCond_Diabetes_Yes</th>\n",
       "      <th>ChronicCond_IschemicHeart_Yes</th>\n",
       "      <th>ChronicCond_Osteoporasis_Yes</th>\n",
       "      <th>ChronicCond_rheumatoidarthritis_Yes</th>\n",
       "      <th>ChronicCond_stroke_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CLM46614</td>\n",
       "      <td>PRV55912</td>\n",
       "      <td>690</td>\n",
       "      <td>1068</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>15000</td>\n",
       "      <td>2670</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>67</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CLM66048</td>\n",
       "      <td>PRV55907</td>\n",
       "      <td>690</td>\n",
       "      <td>1068</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>15000</td>\n",
       "      <td>2670</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>67</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   ClaimID  Provider  InscClaimAmtReimbursed  DeductibleAmtPaid  \\\n",
       "0           0  CLM46614  PRV55912                     690               1068   \n",
       "1           1  CLM66048  PRV55907                     690               1068   \n",
       "\n",
       "   ClaimPeriod  TimeInHptal  Diagnosis Count  Procedures Count  \\\n",
       "0            6            6                9                 0   \n",
       "1            2            2                3                 1   \n",
       "\n",
       "   PotentialFraud  FraudHistory  NoOfMonths_PartACov  NoOfMonths_PartBCov  \\\n",
       "0               1             1                   12                   12   \n",
       "1               0             1                   12                   12   \n",
       "\n",
       "   IPAnnualReimbursementAmt  IPAnnualDeductibleAmt  OPAnnualReimbursementAmt  \\\n",
       "0                     15000                   2670                        60   \n",
       "1                     15000                   2670                        60   \n",
       "\n",
       "   OPAnnualDeductibleAmt  Age  ChronicDisease_Count  SamePhysician_Yes  \\\n",
       "0                     70   67                     7              False   \n",
       "1                     70   67                     7               True   \n",
       "\n",
       "   OPD_Flag_Yes  Gender_Male  Race_Hispanic  Race_Other  Race_White  \\\n",
       "0         False         True          False       False        True   \n",
       "1         False         True          False       False        True   \n",
       "\n",
       "   RenalDiseaseIndicator_Yes  ChronicCond_Alzheimer_Yes  \\\n",
       "0                      False                       True   \n",
       "1                      False                       True   \n",
       "\n",
       "   ChronicCond_Heartfailure_Yes  ChronicCond_KidneyDisease_Yes  \\\n",
       "0                         False                           True   \n",
       "1                         False                           True   \n",
       "\n",
       "   ChronicCond_Cancer_Yes  ChronicCond_ObstrPulmonary_Yes  \\\n",
       "0                   False                           False   \n",
       "1                   False                           False   \n",
       "\n",
       "   ChronicCond_Depression_Yes  ChronicCond_Diabetes_Yes  \\\n",
       "0                        True                      True   \n",
       "1                        True                      True   \n",
       "\n",
       "   ChronicCond_IschemicHeart_Yes  ChronicCond_Osteoporasis_Yes  \\\n",
       "0                           True                         False   \n",
       "1                           True                         False   \n",
       "\n",
       "   ChronicCond_rheumatoidarthritis_Yes  ChronicCond_stroke_Yes  \n",
       "0                                 True                    True  \n",
       "1                                 True                    True  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_encoded['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PotentialFraud\n",
       "0    0.618788\n",
       "1    0.381212\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encoded['PotentialFraud'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_encoded.drop(columns='PotentialFraud')\n",
    "# X = data_encoded[['ClaimID', 'Provider','OPAnnualReimbursementAmt',\n",
    "#  'OPAnnualDeductibleAmt',\n",
    "#  'Age',\n",
    "#  'InscClaimAmtReimbursed',\n",
    "#  'Diagnosis Count',\n",
    "#  'ChronicDisease_Count',\n",
    "#  'IPAnnualReimbursementAmt',\n",
    "#  'ClaimPeriod',\n",
    "#  'Gender_Male',\n",
    "#  'ChronicCond_Alzheimer_Yes',\n",
    "#  'ChronicCond_Osteoporasis_Yes',\n",
    "#  'ChronicCond_Heartfailure_Yes']]\n",
    "y = data_encoded['PotentialFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (390696, 35)\n",
      "X_test: (167442, 35)\n",
      "y_train: (390696,)\n",
      "y_test: (167442,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state= 42, stratify=y)\n",
    "print('X_train:', X_train.shape)\n",
    "print('X_test:', X_test.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('y_test:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///d:/workspace/git_projects/Medicare-Claim-Fraud-Detection/scripts/mlruns/1', creation_time=1728080922230, experiment_id='1', last_update_time=1728080922230, lifecycle_stage='active', name='MedicareClaim_Fraud_Detection', tags={}>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the experiment name\n",
    "experiment_name = \"MedicareClaim_Fraud_Detection\"\n",
    "mlflow.set_experiment(experiment_name)  # Set or create the experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models to evaluate\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(class_weight='balanced', random_state=42),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, X_train, X_test, y_train, y_test):\n",
    "    # Drop non-predictive columns\n",
    "    X_train_processed = X_train.drop(['ClaimID', 'Provider'], axis=1)\n",
    "    X_test_processed = X_test.drop(['ClaimID', 'Provider'], axis=1)\n",
    "\n",
    "    # Iterate through each model\n",
    "    for model_name, model in models.items():\n",
    "        with mlflow.start_run():\n",
    "            # Train the models\n",
    "            model.fit(X_train_processed, y_train)\n",
    "\n",
    "            # Make predictions\n",
    "            y_train_pred = model.predict(X_train_processed)\n",
    "            y_test_pred = model.predict(X_test_processed)\n",
    "\n",
    "            # Calculate metrics\n",
    "            metrics = {\n",
    "                'accuracy': {\n",
    "                    'train': accuracy_score(y_train, y_train_pred),\n",
    "                    'test': accuracy_score(y_test, y_test_pred)\n",
    "                },\n",
    "                'precision': {\n",
    "                    'train': precision_score(y_train, y_train_pred),\n",
    "                    'test': precision_score(y_test, y_test_pred)\n",
    "                },\n",
    "                'recall': {\n",
    "                    'train': recall_score(y_train, y_train_pred),\n",
    "                    'test': recall_score(y_test, y_test_pred)\n",
    "                },\n",
    "                'roc_auc': {\n",
    "                    'train': roc_auc_score(y_train, model.predict_proba(X_train_processed)[:, 1]),\n",
    "                    'test': roc_auc_score(y_test, model.predict_proba(X_test_processed)[:, 1])\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Log metrics with model name included\n",
    "            for metric_name, metric_values in metrics.items():\n",
    "                mlflow.log_metric(f\"{model_name}_train_{metric_name}\", metric_values['train'])\n",
    "                mlflow.log_metric(f\"{model_name}_test_{metric_name}\", metric_values['test'])\n",
    "\n",
    "            # Log feature importance if applicable\n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                feature_importances = model.feature_importances_\n",
    "            elif hasattr(model, 'coef_'):\n",
    "                feature_importances = model.coef_[0]\n",
    "            else:\n",
    "                feature_importances = None\n",
    "\n",
    "            if feature_importances is not None:\n",
    "                # Create a DataFrame for better logging\n",
    "                importance_df = pd.DataFrame({\n",
    "                    'Feature': X_train_processed.columns,\n",
    "                    'Importance': feature_importances\n",
    "                }).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "                # Log the feature importances as an artifact\n",
    "                importance_file_path = f\"{model_name}_feature_importances.csv\"\n",
    "                importance_df.to_csv(importance_file_path, index=False)\n",
    "                mlflow.log_artifact(importance_file_path)\n",
    "\n",
    "            # Log the model\n",
    "            mlflow.sklearn.log_model(model, model_name)\n",
    "\n",
    "            # End the run\n",
    "            mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\workspace\\git_projects\\Medicare-Claim-Fraud-Detection\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "2024/10/04 21:58:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/04 21:58:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/04 21:59:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "d:\\workspace\\git_projects\\Medicare-Claim-Fraud-Detection\\.venv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [21:59:57] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2024/10/04 22:00:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "# Call the function to evaluate the models\n",
    "evaluate_models(models, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run this in CMD:\n",
    "\n",
    "mlflow ui --backend-store-uri \"mssql+pyodbc://ROHIT/MedicareClaim?driver=ODBC+Driver+17+for+SQL+Server`&trusted_connection=yes\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Random Forest\n",
    "# start_time = time.time()\n",
    "\n",
    "# rf_model = RandomForestClassifier(n_estimators= 100,random_state=42)\n",
    "# rf_model.fit(X_train.drop(['ClaimID', 'Provider'], axis=1), y_train)\n",
    "# y_pred_rf = rf_model.predict(X_test.drop(['ClaimID', 'Provider'], axis=1))\n",
    "# end_time = time.time()\n",
    "# # Time taken\n",
    "# execution_time = end_time - start_time\n",
    "# print('Execution time: ', execution_time)\n",
    "# print(\"Random Forest Classifier Report:\")\n",
    "# print(classification_report(y_test, y_pred_rf))\n",
    "# print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time:  22.997344732284546\n",
      "\n",
      "Random Forest Classifier Training Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.99      0.84    241758\n",
      "           1       0.97      0.41      0.58    148938\n",
      "\n",
      "    accuracy                           0.77    390696\n",
      "   macro avg       0.85      0.70      0.71    390696\n",
      "weighted avg       0.82      0.77      0.74    390696\n",
      "\n",
      "Training Accuracy: 0.7714335442389991\n",
      "Training Precision: 0.9698125098471719\n",
      "Training Recall: 0.4132860653426258\n",
      "Training F1 Score: 0.5795826899175173\n",
      "\n",
      "Random Forest Classifier Test Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.99      0.84    103611\n",
      "           1       0.97      0.41      0.58     63831\n",
      "\n",
      "    accuracy                           0.77    167442\n",
      "   macro avg       0.85      0.70      0.71    167442\n",
      "weighted avg       0.82      0.77      0.74    167442\n",
      "\n",
      "Test Accuracy: 0.7711506073744938\n",
      "Test Precision: 0.9693847512511039\n",
      "Test Recall: 0.4127148250849901\n",
      "Test F1 Score: 0.578944476798488\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize and fit the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split = 7, random_state=42)\n",
    "rf_model.fit(X_train.drop(['ClaimID', 'Provider'], axis=1), y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf_train = rf_model.predict(X_train.drop(['ClaimID', 'Provider'], axis=1))\n",
    "y_pred_rf_test = rf_model.predict(X_test.drop(['ClaimID', 'Provider'], axis=1))\n",
    "\n",
    "end_time = time.time()\n",
    "# Time taken\n",
    "execution_time = end_time - start_time\n",
    "print('Execution time: ', execution_time)\n",
    "\n",
    "# Metrics for Training Data\n",
    "print(\"\\nRandom Forest Classifier Training Report:\")\n",
    "print(classification_report(y_train, y_pred_rf_train))\n",
    "print(f\"Training Accuracy: {accuracy_score(y_train, y_pred_rf_train)}\")\n",
    "print(f\"Training Precision: {precision_score(y_train, y_pred_rf_train)}\")\n",
    "print(f\"Training Recall: {recall_score(y_train, y_pred_rf_train)}\")\n",
    "print(f\"Training F1 Score: {f1_score(y_train, y_pred_rf_train)}\")\n",
    "\n",
    "# Metrics for Test Data\n",
    "print(\"\\nRandom Forest Classifier Test Report:\")\n",
    "print(classification_report(y_test, y_pred_rf_test))\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred_rf_test)}\")\n",
    "print(f\"Test Precision: {precision_score(y_test, y_pred_rf_test)}\")\n",
    "print(f\"Test Recall: {recall_score(y_test, y_pred_rf_test)}\")\n",
    "print(f\"Test F1 Score: {f1_score(y_test, y_pred_rf_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                Feature  Importance\n",
      "6                          FraudHistory    0.888056\n",
      "15                    SamePhysician_Yes    0.016385\n",
      "16                         OPD_Flag_Yes    0.015597\n",
      "3                           TimeInHptal    0.013461\n",
      "1                     DeductibleAmtPaid    0.012137\n",
      "5                      Procedures Count    0.006569\n",
      "4                       Diagnosis Count    0.004834\n",
      "11             OPAnnualReimbursementAmt    0.004670\n",
      "13                                  Age    0.004624\n",
      "0                InscClaimAmtReimbursed    0.004490\n",
      "9              IPAnnualReimbursementAmt    0.003906\n",
      "12                OPAnnualDeductibleAmt    0.003881\n",
      "19                           Race_Other    0.003698\n",
      "2                           ClaimPeriod    0.003533\n",
      "14                 ChronicDisease_Count    0.002187\n",
      "10                IPAnnualDeductibleAmt    0.001977\n",
      "18                        Race_Hispanic    0.001697\n",
      "17                          Gender_Male    0.000693\n",
      "20                           Race_White    0.000624\n",
      "30         ChronicCond_Osteoporasis_Yes    0.000592\n",
      "27           ChronicCond_Depression_Yes    0.000575\n",
      "32               ChronicCond_stroke_Yes    0.000551\n",
      "21            RenalDiseaseIndicator_Yes    0.000546\n",
      "26       ChronicCond_ObstrPulmonary_Yes    0.000525\n",
      "24        ChronicCond_KidneyDisease_Yes    0.000519\n",
      "25               ChronicCond_Cancer_Yes    0.000509\n",
      "22            ChronicCond_Alzheimer_Yes    0.000507\n",
      "31  ChronicCond_rheumatoidarthritis_Yes    0.000498\n",
      "28             ChronicCond_Diabetes_Yes    0.000488\n",
      "23         ChronicCond_Heartfailure_Yes    0.000477\n",
      "29        ChronicCond_IschemicHeart_Yes    0.000467\n",
      "8                   NoOfMonths_PartBCov    0.000389\n",
      "7                   NoOfMonths_PartACov    0.000336\n"
     ]
    }
   ],
   "source": [
    "importances = rf_model.feature_importances_\n",
    "feature_names = X.drop(['ClaimID', 'Provider'], axis=1).columns\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "feature_importance_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OPAnnualReimbursementAmt',\n",
       " 'OPAnnualDeductibleAmt',\n",
       " 'Age',\n",
       " 'InscClaimAmtReimbursed',\n",
       " 'Diagnosis Count',\n",
       " 'ChronicDisease_Count',\n",
       " 'IPAnnualReimbursementAmt',\n",
       " 'ClaimPeriod',\n",
       " 'Gender_Male',\n",
       " 'ChronicCond_Alzheimer_Yes',\n",
       " 'ChronicCond_Osteoporasis_Yes',\n",
       " 'ChronicCond_Heartfailure_Yes']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df['Feature'][:12].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.93      0.76    103611\n",
      "           1       0.54      0.12      0.20     63831\n",
      "\n",
      "    accuracy                           0.63    167442\n",
      "   macro avg       0.59      0.53      0.48    167442\n",
      "weighted avg       0.60      0.63      0.54    167442\n",
      "\n",
      "Accuracy: 0.6255658675839992\n"
     ]
    }
   ],
   "source": [
    "y_pred_dt = lr_model.predict(X_test.drop(['ClaimID', 'Provider'], axis=1))\n",
    "\n",
    "print(\"Logistic Regression Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_dt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
